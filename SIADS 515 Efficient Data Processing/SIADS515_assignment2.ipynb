{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please add your name and University of Michagan uniqname here...\n",
    "\n",
    "NAME = 'Ilana Multak'\n",
    "UMICH_UNIQNAME = 'imultak'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d06f9d3c2cee7a67177df71b6bcacabf",
     "grade": false,
     "grade_id": "cell-5301009c929e05f9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v2.3.06012'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "019d2905e75d0c87141bbcf5b0abbbf2",
     "grade": false,
     "grade_id": "cell-eece325edeb92b93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# SIADS 515 Week 2 Homework (HW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "addc3081907b61c48684d895fe502b45",
     "grade": false,
     "grade_id": "cell-95eed09f5442ed9d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "A Pandas DataFrame can be populated with a generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4997158e7dd772a526f576425747290b",
     "grade": false,
     "grade_id": "cell-de1cc3a77fdfc464",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def gen_three_data():\n",
    "    '''\n",
    "    Generate 3 dictionaries with keys A and B\n",
    "    '''\n",
    "    for i in range(3):\n",
    "        yield {\n",
    "            \"A\": i + 1, # simple\n",
    "            \"B\": (i + 1) * 10, # some math\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84a7029b446886278d9ccb22a080fba5",
     "grade": false,
     "grade_id": "cell-7a7f86e26a4bbc65",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1  10\n",
       "1  2  20\n",
       "2  3  30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data=gen_three_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c73f4f403060f22079999f17bd951268",
     "grade": false,
     "grade_id": "cell-ef43a9ba0c299adb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can also add a parameter to the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "111491808734537d5984944506fbfdb8",
     "grade": false,
     "grade_id": "cell-db348e84064ba3aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gen_some_data(n):\n",
    "    '''\n",
    "    Generate n dictionaries with keys A, B and C\n",
    "    '''\n",
    "    for i in range(n):\n",
    "        yield {\n",
    "            \"A\": i + 1, # simple\n",
    "            \"B\": (i + 1) * 10, # some math\n",
    "            \"C\": np.random.randn() # a random number drawn from a standard normal distribution\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c42f454731056f81e3ae9aff06d16b23",
     "grade": false,
     "grade_id": "cell-1f2fd49e2c32b5a4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.414621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.142670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1.315254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.054605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.924403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>-0.093163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>1.825352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.738571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>0.574966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.244715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B         C\n",
       "0   1   10  1.414621\n",
       "1   2   20  0.142670\n",
       "2   3   30  1.315254\n",
       "3   4   40 -0.054605\n",
       "4   5   50 -0.924403\n",
       "5   6   60 -0.093163\n",
       "6   7   70  1.825352\n",
       "7   8   80 -0.738571\n",
       "8   9   90  0.574966\n",
       "9  10  100  0.244715"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data=gen_some_data(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3383277a59c998a4ab77341c765a06bb",
     "grade": false,
     "grade_id": "cell-972abedfa5a0b3db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "There are times when using this technique can be a nice way to solve problems that would be hard to solve in other ways.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db964789926e67694216f4653b5ab42f",
     "grade": false,
     "grade_id": "cell-9c84b5439b4053be",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "We need to get the data from the file `assets/companies_small_set.data` into a DataFrame. The problem is that the data on each line of the file is in either a [JSON](https://en.wikipedia.org/wiki/JSON) or [Tab-separated values (TSV)](https://en.wikipedia.org/wiki/Tab-separated_values) format.\n",
    "\n",
    "The JSON lines are in the correct format, they just need to be converted to native Python `dict`s.\n",
    "\n",
    "The TSV lines need to be converted in to `dict`s that match the JSON format.\n",
    "\n",
    "Write a generator `gen_fixed_data` that takes an iterator as an arguement. It should parse the values in the iterator and yield each value in the correct format: A `dict` with the keys:\n",
    "\n",
    "- company\n",
    "- catch_phrase\n",
    "- phone\n",
    "- timezone\n",
    "- client_count\n",
    "\n",
    "**Note that your solution should be a generator function, it should not return a DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e921705c7f5e2317ec09363b2d3bea85",
     "grade": false,
     "grade_id": "cell-567498783830b462",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "file = open( \"assets/companies_small_set.data\", 'r')\n",
    "data_iterator = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fix_data(data_iterator):\n",
    "    keys = None\n",
    "\n",
    "    for line in data_iterator:\n",
    "        line = line.strip()\n",
    "        try:\n",
    "            d = json.loads(line)\n",
    "            keys = [\n",
    "                  (key, type(value)) \n",
    "                  for key, value in d.items()\n",
    "             ]\n",
    "            yield d\n",
    "        except json.JSONDecodeError:\n",
    "            tsv_data = line.split(\"\\t\")\n",
    "            tsv_key_val = {key: dtype(value) for value, (key, dtype) in zip(tsv_data, keys)}\n",
    "            yield tsv_key_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>catch_phrase</th>\n",
       "      <th>phone</th>\n",
       "      <th>timezone</th>\n",
       "      <th>client_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watkins Inc</td>\n",
       "      <td>Integrated radical installation</td>\n",
       "      <td>7712422719</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bennett and Sons</td>\n",
       "      <td>Persistent contextually-based standardization</td>\n",
       "      <td>018.666.0600</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferguson-Garner</td>\n",
       "      <td>Multi-layered tertiary neural-net</td>\n",
       "      <td>(086)401-8955x53502</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pennington PLC</td>\n",
       "      <td>Future-proofed tertiary frame</td>\n",
       "      <td>+1-312-296-2956x137</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perry PLC</td>\n",
       "      <td>Managed full-range secured line</td>\n",
       "      <td>825-403-2850x005</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            company                                   catch_phrase  \\\n",
       "0       Watkins Inc                Integrated radical installation   \n",
       "1  Bennett and Sons  Persistent contextually-based standardization   \n",
       "2   Ferguson-Garner              Multi-layered tertiary neural-net   \n",
       "3    Pennington PLC                  Future-proofed tertiary frame   \n",
       "4         Perry PLC                Managed full-range secured line   \n",
       "\n",
       "                 phone                      timezone  client_count  \n",
       "0           7712422719              America/New_York           442  \n",
       "1         018.666.0600           America/Los_Angeles           492  \n",
       "2  (086)401-8955x53502           America/Los_Angeles           528  \n",
       "3  +1-312-296-2956x137  America/Indiana/Indianapolis           638  \n",
       "4     825-403-2850x005               America/Chicago           474  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result = gen_fix_data(data_iterator)\n",
    "Data = []\n",
    "for each_dict in Result:\n",
    "#     appending each_dict to Data for creating a DataFrame\n",
    "    Data.append(each_dict)\n",
    "# Let's convert Result into DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(Data)\n",
    "# Let's see the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21ff21874b30e2f34178c0e2846b5a5f",
     "grade": false,
     "grade_id": "cell-703ebc6034ff592d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "If the generator is correctly fixing the data formats, we should be able to use it to populate a DataFrame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>catch_phrase</th>\n",
       "      <th>phone</th>\n",
       "      <th>timezone</th>\n",
       "      <th>client_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watkins Inc</td>\n",
       "      <td>Integrated radical installation</td>\n",
       "      <td>7712422719</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bennett and Sons</td>\n",
       "      <td>Persistent contextually-based standardization</td>\n",
       "      <td>018.666.0600</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferguson-Garner</td>\n",
       "      <td>Multi-layered tertiary neural-net</td>\n",
       "      <td>(086)401-8955x53502</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pennington PLC</td>\n",
       "      <td>Future-proofed tertiary frame</td>\n",
       "      <td>+1-312-296-2956x137</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perry PLC</td>\n",
       "      <td>Managed full-range secured line</td>\n",
       "      <td>825-403-2850x005</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brown-Knight</td>\n",
       "      <td>Reverse-engineered intangible model</td>\n",
       "      <td>+1-388-334-1572</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vargas Group</td>\n",
       "      <td>Ameliorated tangible software</td>\n",
       "      <td>001-724-417-1375x0152</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Collins, Hanson and Flores</td>\n",
       "      <td>Future-proofed leadingedge moratorium</td>\n",
       "      <td>894-945-1213</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jones-Mcmahon</td>\n",
       "      <td>Multi-lateral directional interface</td>\n",
       "      <td>001-581-051-4431x5960</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Herrera-Young</td>\n",
       "      <td>Networked disintermediate structure</td>\n",
       "      <td>(663)944-2205</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company                                   catch_phrase  \\\n",
       "0                 Watkins Inc                Integrated radical installation   \n",
       "1            Bennett and Sons  Persistent contextually-based standardization   \n",
       "2             Ferguson-Garner              Multi-layered tertiary neural-net   \n",
       "3              Pennington PLC                  Future-proofed tertiary frame   \n",
       "4                   Perry PLC                Managed full-range secured line   \n",
       "5                Brown-Knight            Reverse-engineered intangible model   \n",
       "6                Vargas Group                  Ameliorated tangible software   \n",
       "7  Collins, Hanson and Flores          Future-proofed leadingedge moratorium   \n",
       "8               Jones-Mcmahon            Multi-lateral directional interface   \n",
       "9               Herrera-Young            Networked disintermediate structure   \n",
       "\n",
       "                   phone                      timezone  client_count  \n",
       "0             7712422719              America/New_York           442  \n",
       "1           018.666.0600           America/Los_Angeles           492  \n",
       "2    (086)401-8955x53502           America/Los_Angeles           528  \n",
       "3    +1-312-296-2956x137  America/Indiana/Indianapolis           638  \n",
       "4       825-403-2850x005               America/Chicago           474  \n",
       "5        +1-388-334-1572              America/New_York           453  \n",
       "6  001-724-417-1375x0152               America/Chicago           676  \n",
       "7           894-945-1213           America/Los_Angeles           389  \n",
       "8  001-581-051-4431x5960              America/New_York           460  \n",
       "9          (663)944-2205              America/New_York           816  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('assets/companies_small_set.data', 'r') as broken_data:\n",
    "    df = pd.DataFrame(data=gen_fix_data(broken_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ea24d42b16ba65d31c16e46cd5272b5",
     "grade": true,
     "grade_id": "cell-3a982105c457dac0",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell runs a series of assert statements to grade your solution.\n",
    "\n",
    "with open('assets/companies_small_set.data', 'r') as broken_data:\n",
    "    gen = gen_fix_data(broken_data)\n",
    "    \n",
    "    # Let's make sure gen_fix_data is a generator function...\n",
    "    from types import GeneratorType\n",
    "    assert type(gen) == GeneratorType, 'wrong type, should be a generator'\n",
    "    \n",
    "\n",
    "    # Check the first entry from companies_small_set.data...\n",
    "    entry1 = next(gen)\n",
    "    assert entry1['company'] == \"Watkins Inc\", 'incorrect value for entry1[\"company\"]'\n",
    "    assert entry1['catch_phrase'] == \"Integrated radical installation\", \\\n",
    "        'incorrect value for entry1[\"catch_phrase\"]'\n",
    "    assert entry1['phone'] == '7712422719', 'incorrect value for entry1[\"phone\"]'\n",
    "    assert entry1['timezone'] == \"America/New_York\", 'incorrect value for entry1[\"timezone\"]'\n",
    "    assert type(entry1['client_count']) == int, 'entry1[\"client_count\"] is not an int'\n",
    "    assert entry1['client_count'] == 442, 'incorrect value for entry1[\"client_count\"]'\n",
    "\n",
    "    # Check the second entry from companies_small_set.data...\n",
    "    entry2 = next(gen)\n",
    "    assert entry2['company'] == \"Bennett and Sons\", 'incorrect value for entry2[\"company\"]'\n",
    "    assert entry2['catch_phrase'] == \"Persistent contextually-based standardization\", \\\n",
    "        'incorrect value for entry2[\"catch_phrase\"]'\n",
    "    assert entry2['phone'] == \"018.666.0600\", 'incorrect value for entry2[\"phone\"]'\n",
    "    assert entry2['timezone'] == \"America/Los_Angeles\", 'incorrect value for entry2[\"timezone\"]'\n",
    "    assert type(entry2['client_count']) == int, 'entry2[\"client_count\"] is not an int'\n",
    "    assert entry2['client_count'] == 492, 'incorrect value for entry2[\"client_count\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c70c36116707e03dfc2d9169b90da7",
     "grade": true,
     "grade_id": "cell-032e79174069cec9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mgen_fix_data\u001b[0;34m(data_iterator)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m           (key, \u001b[38;5;28mtype\u001b[39m(value)) \n\u001b[1;32m     10\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     11\u001b[0m      ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m      4\u001b[0m test_data \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mStringIO(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChang, Fisher and Green\tOpen-architected foreground productivity\t759.382.4219\t\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmerica/Los_Angeles\t770\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerica/New_York\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_count\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 634}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_fix_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m correct \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChang, Fisher and Green\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatch_phrase\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen-architected foreground productivity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphone\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m759.382.4219\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m634\u001b[39m},\n\u001b[1;32m     36\u001b[0m ])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(generated) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(correct), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrong number of rows\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:710\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    708\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data[\u001b[38;5;241m0\u001b[39m]):\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mgen_fix_data\u001b[0;34m(data_iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m     14\u001b[0m     tsv_data \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     tsv_key_val \u001b[38;5;241m=\u001b[39m {key: dtype(value) \u001b[38;5;28;01mfor\u001b[39;00m value, (key, dtype) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtsv_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m tsv_key_val\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# This cell runs a series of assert statements to grade your solution against different data.\n",
    "import io\n",
    "\n",
    "test_data = io.StringIO(\n",
    "    'Chang, Fisher and Green\tOpen-architected foreground productivity\t759.382.4219\t'\n",
    "        'America/Los_Angeles\t770\\n'\n",
    "    'Patel, Thornton and Guzman\tCustomizable asynchronous approach\t+1-578-156-5938x77840\t'\n",
    "        'America/Los_Angeles\t418\\n'\n",
    "    'Smith-Cortez\tIntegrated solution-oriented moratorium\t7535139332\t'\n",
    "        'America/Los_Angeles\t634\\n'\n",
    "    '{\"company\": \"Miller-Flores\", \"catch_phrase\": \"Object-based user-facing array\", \"phone\": \"(185)839-8947x19659\", '\n",
    "        '\"timezone\": \"America/New_York\", \"client_count\": 634}\\n'\n",
    ")\n",
    "generated = pd.DataFrame(gen_fix_data(test_data))\n",
    "\n",
    "correct = pd.DataFrame([{'company': 'Chang, Fisher and Green',\n",
    "  'catch_phrase': 'Open-architected foreground productivity',\n",
    "  'phone': '759.382.4219',\n",
    "  'timezone': 'America/Los_Angeles',\n",
    "  'client_count': 770},\n",
    " {'company': 'Patel, Thornton and Guzman',\n",
    "  'catch_phrase': 'Customizable asynchronous approach',\n",
    "  'phone': '+1-578-156-5938x77840',\n",
    "  'timezone': 'America/Los_Angeles',\n",
    "  'client_count': 418},\n",
    " {'company': 'Smith-Cortez',\n",
    "  'catch_phrase': 'Integrated solution-oriented moratorium',\n",
    "  'phone': '7535139332',\n",
    "  'timezone': 'America/Los_Angeles',\n",
    "  'client_count': 634},\n",
    " {'company': 'Miller-Flores',\n",
    "  'catch_phrase': 'Object-based user-facing array',\n",
    "  'phone': '(185)839-8947x19659',\n",
    "  'timezone': 'America/New_York',\n",
    "  'client_count': 634},\n",
    "])\n",
    "\n",
    "assert len(generated) == len(correct), 'wrong number of rows'\n",
    "assert all(g == c for g, c in zip(generated.columns.sort_values(), correct.columns.sort_values())), \\\n",
    "    'columns names do not match'\n",
    "\n",
    "for col in generated.columns:\n",
    "    for i in range(len(generated)):\n",
    "        assert generated[col][i] == correct[col][i], \\\n",
    "            f'wrong value at column \"{col}\", index \"{i}\", {generated[col][i]} != {correct[col][i]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c2bc159fd1bde06702e5a7d235f60f5",
     "grade": false,
     "grade_id": "cell-9b969d24b31e6cdc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "The data in `assets/server_metrics.csv` represents the time it take to handle requests in a start-up company's web application. Let's imagine we are asked to write some code that gives us a DataFrame that just contains the entries where `processing_time` is greater than 160 milliseconds.\n",
    "\n",
    "We could solve that problem like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe95294466e066a4832fb3f815c6299f",
     "grade": false,
     "grade_id": "cell-f31d431975ffcadf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/server_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2317c1cbb10317fcea215824298ec0e9",
     "grade": false,
     "grade_id": "cell-86de740c3939d00a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "outliers = df[df['processing_time'] > 160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0fb6e2b186bf4deb353f1caca62a3a3",
     "grade": false,
     "grade_id": "cell-6dc25509456a710c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = outliers['processing_time'].plot.hist(title=\"Times > 160\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2823b07fbe60281b9fd4ac67afa5ff87",
     "grade": false,
     "grade_id": "cell-2b214c85baa0653e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "But imagine that instead of dealing with millions of rows, we have to deal with billions or trillions and the set is too big to fit comfortably in memory, or that the data is coming to us not in a local file, but is being read over the network. Generators can be a nice way to help in that situation.\n",
    "\n",
    "Here is a generator that yields a `dict` for each line in `assets/server_metrics.csv`.\n",
    "\n",
    "**Note that your solution should be a generator function, it should not return a DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c939592ecb519922c5041e76c68be28",
     "grade": false,
     "grade_id": "cell-a4b49ae55ad541d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def metrics_stream():\n",
    "    '''\n",
    "    Generate dictionaries from each line in assets/server_metrics.csv\n",
    "    '''\n",
    "    import csv\n",
    "\n",
    "    with open('assets/server_metrics.csv', 'r') as stream:\n",
    "        csv_stream = csv.DictReader(stream, ['job_id', 'processing_time', 'instance_id'])\n",
    "        next(csv_stream) # throw away header row\n",
    "        for entry in csv_stream:\n",
    "            entry['processing_time'] = float(entry['processing_time'])\n",
    "            yield dict(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39bfdaeffe8a043ab88c150259fce713",
     "grade": false,
     "grade_id": "cell-7056aaf97d502d15",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For this problem, write a generator that can be used to create a DataFrame like the `outliers` one above. Its first parameter should be the iterable we get from the `metrics_stream()` generator function. Its second (optional) parameter should be called `lower_bound` and be used to filter out entries whose \"processing_time\" is less than or equal to this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e006169bdc3ce0553e943ed409b56dbd",
     "grade": false,
     "grade_id": "cell-f4de2a9b5ed655d5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gen_outliers(metrics_iterable, lower_bound=160):\n",
    "    \n",
    "    for entry in metrics_iterable:\n",
    "        time = str(entry['processing_time']).split(\".\")[0]\n",
    "        if int(time) >= lower_bound :\n",
    "                yield dict(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2aed6c9e4f9fe7d54cb36ba0cb6705a2",
     "grade": false,
     "grade_id": "cell-1a58493b608efae7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "metrics_gen = metrics_stream() \n",
    "\n",
    "generated_outliers = pd.DataFrame(gen_outliers(metrics_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d8114b60952197387a0856b033c1c84",
     "grade": false,
     "grade_id": "cell-906eabdca6f8bf51",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This should generate the same plot as the plot above\n",
    "_ = generated_outliers['processing_time'].plot.hist(title=\"Times > 160\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09e785fc998e6612c9ec4dcec69a11b5",
     "grade": true,
     "grade_id": "cell-4428c833fa7ec7b7",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell runs a series of assert statements to grade your solution.\n",
    "\n",
    "gen = gen_outliers(metrics_stream())\n",
    "    \n",
    "# Let's make sure gen_fix_data is a generator function...\n",
    "from types import GeneratorType\n",
    "assert type(gen) == GeneratorType, 'wrong type, should be a generator'\n",
    "\n",
    "# check that data matches\n",
    "\n",
    "outliers_160 = pd.DataFrame(gen_outliers(metrics_stream(), lower_bound=160))\n",
    "assert len(outliers_160) == 2615, 'wrong number of entries for lower_bound=160'\n",
    "\n",
    "outliers_150 = pd.DataFrame(gen_outliers(metrics_stream(), lower_bound=150))\n",
    "assert len(outliers_150) == 556826, 'wrong number of entries for lower_bound=150'\n",
    "\n",
    "outliers_170 = pd.DataFrame(gen_outliers(metrics_stream(), lower_bound=170))\n",
    "assert len(outliers_170) == 9, 'wrong number of entries for lower_bound=170'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "332a3d73431d0ed04975effee85cb6f2",
     "grade": true,
     "grade_id": "cell-13bda9b1a4935df5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell runs a series of assert statements to grade your solution against different data.\n",
    "import io\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        'job_id': '336',\n",
    "        'processing_time': 150.83086863345971,\n",
    "        'instance_id': '1346846',\n",
    "    },\n",
    "    {\n",
    "        'job_id': '337',\n",
    "        'processing_time': 168.37830864466645,\n",
    "        'instance_id': '1349783',\n",
    "    },\n",
    "    {\n",
    "         'job_id': '338',\n",
    "         'processing_time': 148.8572313268281,\n",
    "         'instance_id': '1345472',\n",
    "    },\n",
    "    {\n",
    "        'job_id': '339',\n",
    "        'processing_time': 148.39006806562258,\n",
    "        'instance_id': '1347784',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "outliers_160 = pd.DataFrame(gen_outliers(test_data, lower_bound=160))\n",
    "assert len(outliers_160) == 1, 'wrong number of entries for lower_bound=160'\n",
    "\n",
    "outliers_150 = pd.DataFrame(gen_outliers(test_data, lower_bound=150))\n",
    "assert len(outliers_150) == 2, 'wrong number of entries for lower_bound=150'\n",
    "\n",
    "outliers_170 = pd.DataFrame(gen_outliers(test_data, lower_bound=170))\n",
    "assert len(outliers_170) == 0, 'wrong number of entries for lower_bound=170'"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_efficient_data_processing_v3_assignment2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
