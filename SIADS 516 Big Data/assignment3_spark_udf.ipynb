{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "8xKUiifPp32x",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03a3d471723919640c6afdf62f40975f",
     "grade": false,
     "grade_id": "cell-6b7fdfa930d77221",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SIADS 516: Homework 3\n",
    "\n",
    "- **Dr. Chris Teplovs**, School of Information, University of Michigan\n",
    "- **Kris Steinhoff**, School of Information, University of Michigan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbfc8c28efd166e58f0a7c342326c2be",
     "grade": false,
     "grade_id": "cell-c60fc9d05ab1488d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This homework assignment builds on the Spark DataFrame material we covered in class.\n",
    "\n",
    "You will be using a compressed version of the Yelp Academic Dataset.  The data set is provided for you in the assets/data/yelp_academic of your workspace and you should not need to download it again if you're working on the Coursera hosted notebook environment.\n",
    "\n",
    "You might want to refer to the lecture companion notebooks (in resources/lecture_notebooks/ or equivalently via Coursera as \"Ungraded Lab: Spark Core Demo\" and \"Ungraded Lab: Spark SQL Demo) for hints about libraries to import, etc.\n",
    "\n",
    "You will notice that there are a **lot** of reviews.  You might want to work off a small sample (i.e. use the sample() function in Spark) to work on a reduced size dataset while you're developing your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9eaf180ea143f9255b5e744fc534936",
     "grade": false,
     "grade_id": "cell-58e2fd655ada3555",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The AutograderHelper class provides methods used by the autograder.\n",
    "from autograder_helper import AutograderHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0477ef5614295bf8caf6e1096266bfa3",
     "grade": true,
     "grade_id": "inject_private_helper",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 0 points.\n",
    "# This cell has hidden code used to configure the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5acc488dcb25bdbf68a5a61a683cb329",
     "grade": false,
     "grade_id": "cell-59a22c3dbff11ad2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/24 13:44:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('My First Spark application') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09138434c9157bb972fb5311e3452059",
     "grade": false,
     "grade_id": "cell-2fe6f169887280fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Set up some RDDs:\n",
    "user = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_user.json.gz')\n",
    "review = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_review.json.gz')\n",
    "checkin = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_checkin.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import * \n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 5 µs, total: 13 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf, explode\n",
    "from pyspark.sql.types import ArrayType,StringType\n",
    "from pyspark.sql.functions import hour, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'cool',\n",
       " 'date',\n",
       " 'funny',\n",
       " 'review_id',\n",
       " 'stars',\n",
       " 'text',\n",
       " 'useful',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b5ce90448f11d395ec5cd997bf6e429",
     "grade": false,
     "grade_id": "cell-c4995d5242cd1768",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- COOL COMPLIMENTS --\n",
    "\n",
    "Determine how many users have received more than 5000 \"cool\" compliments.\n",
    "\n",
    "- Create a variable `user_count` (an integer) which contains the number of user with more than 5000 \"cool\" compliments (using the `compliment_cool` field.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5c0e1e3c90fac25a0cdc87d430e9652",
     "grade": false,
     "grade_id": "cell-66bc2f2a925467c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "user1 = user.filter(user['compliment_cool'] > 5000).collect()\n",
    "user_count = len(user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a28f6e005f28828aa341bc6552ef3077",
     "grade": false,
     "grade_id": "cell-123aa59e04fda184",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(user_count) == int, \"The user_count variable should be an integer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a301b60a72d2b0c5989036e763ed67e",
     "grade": true,
     "grade_id": "cell-167a913f1dc689ce",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 2 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29f4bcd3be69bb93084cf273b04f7de6",
     "grade": false,
     "grade_id": "cell-8044ac07d496501d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- USEFUL POSITIVE REVIEWS --\n",
    "\n",
    "Determine the top 5 most useful positive reviews.\n",
    "\n",
    "- Create a variable `top_5_useful_positive`. This should be a PySpark DataFrame\n",
    "- For this question a \"positive review\" is one with 4 or 5 stars\n",
    "- The DataFrame should be ordered by `useful` and contain 5 rows\n",
    "- The DataFrame should have these columns:\n",
    "    - `review_id`\n",
    "    - `useful`\n",
    "    - `stars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 68.9 ms, total: 206 ms\n",
      "Wall time: 44.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1lGXlyq4MALOMx17vpBcoQ</td>\n",
       "      <td>358</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gAUkgn4dTO-R2n5LBcht-w</td>\n",
       "      <td>278</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5S985RjfmDJYsJvUt-3uJQ</td>\n",
       "      <td>244</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0nr6SQFKpR6JCYl1zrzROQ</td>\n",
       "      <td>241</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-hRpmcavsC0UDI_QsQsUcA</td>\n",
       "      <td>235</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  useful  stars\n",
       "0  1lGXlyq4MALOMx17vpBcoQ     358    5.0\n",
       "1  gAUkgn4dTO-R2n5LBcht-w     278    5.0\n",
       "2  5S985RjfmDJYsJvUt-3uJQ     244    4.0\n",
       "3  0nr6SQFKpR6JCYl1zrzROQ     241    5.0\n",
       "4  -hRpmcavsC0UDI_QsQsUcA     235    4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "top_5_useful_positive = review['review_id','useful','stars'].filter(review['stars'] >= 4) \\\n",
    "                                                 .sort(col(\"useful\").desc()).head(5)\n",
    "\n",
    "top_5_useful_positive = spark.createDataFrame(top_5_useful_positive)\n",
    "\n",
    "top_5_useful_positive = top_5_useful_positive.select(top_5_useful_positive.review_id, top_5_useful_positive.useful, top_5_useful_positive.stars)\n",
    "\n",
    "top_5_useful_positive.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd33677345bfe6594a9ab1cc4f868e84",
     "grade": false,
     "grade_id": "cell-54c8c4e7596531e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81f2c69737da9d2deb2acdcc3c2964e4",
     "grade": false,
     "grade_id": "cell-0b3e82dd685d24d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "assert type(top_5_useful_positive) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The top_useful_positive variable should be a Spark DataFrame.\"\n",
    "\n",
    "submitted = AutograderHelper.parse_spark_dataframe(top_5_useful_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "465146a4e784cd70917bb9b3b6fcf3d4",
     "grade": true,
     "grade_id": "cell-af0f871a7824a9cd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 1 point (out of 20). This cell does not contain hidden tests.\n",
    "# This cell deliberately includes answers to provide guidance on how this question is graded.\n",
    "\n",
    "assert len(submitted) == 5, \\\n",
    "    \"The result must have 5 rows.\"\n",
    "\n",
    "top_useful_review_id = \"1lGXlyq4MALOMx17vpBcoQ\"\n",
    "assert submitted[\"review_id\"][0] == top_useful_review_id, \\\n",
    "    f'The first row should have review_id \"{top_useful_review_id}\" (this review has the most \"useful\" ratings)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34b82eb96d4e50545169a20166fc0fbd",
     "grade": true,
     "grade_id": "cell-e95ff3117c1fb4df",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 4 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c81e192adce8d5297300371d1d4d90a",
     "grade": false,
     "grade_id": "cell-89161ab4899d135c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- CHECKINS --\n",
    "\n",
    "Determine what hours of the day most checkins occur.\n",
    "\n",
    "- Create a variable `hours_by_checkin_count`. This should be a PySpark DataFrame\n",
    "- The DataFrame should be ordered by `count` and contain 24 rows\n",
    "- The DataFrame should have these columns:\n",
    "    - `hour` (the hour of the day as an integer, 0-23)\n",
    "    - `count` (the number of checkins that occurred in that hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkin.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(business_id='--1UhMGODdWsrMastO9DZw', date='2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016-10-15 02:45:18, 2016-11-18 01:54:50, 2017-04-20 18:39:06, 2017-05-03 17:58:02')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         business_id|                date|\n",
      "+--------------------+--------------------+\n",
      "|--1UhMGODdWsrMast...|2016-04-26 19:49:...|\n",
      "|--6MefnULPED_I942...|2011-06-04 18:22:...|\n",
      "|--7zmmkVg-IMGaXbu...|2014-12-29 19:25:...|\n",
      "|--8LPVSo5i0Oo61X0...| 2016-07-08 16:43:30|\n",
      "|--9QQLMTbFzLJ_oT-...|2010-06-26 17:39:...|\n",
      "|--9e1ONYQuAa-CB_R...|2010-02-08 05:56:...|\n",
      "|--DaPTJW3-tB1vP-P...|2012-06-03 17:46:...|\n",
      "|--DdmeR16TRb3LsjG...|2012-11-02 21:26:...|\n",
      "|--EF5N7P70J_UYBTP...|2018-05-25 19:52:...|\n",
      "|--EX4rRznJrltyn-3...|2010-02-26 17:05:...|\n",
      "|--FBCX-N37CMYDfs7...|2010-05-31 07:57:...|\n",
      "|--FLdgM0GNpXVMn74...|2012-10-23 18:47:...|\n",
      "|--GM_ORV2cYS-h38D...|2011-09-11 18:16:...|\n",
      "|--Gc998IMjLn8yr-H...| 2014-07-01 01:20:47|\n",
      "|--I7YYLada0tSLkOR...|2014-11-07 00:51:...|\n",
      "|--KCl2FvVQpvjzmZS...|2011-07-29 16:53:...|\n",
      "|--KQsXc-clkO7oHRq...|2010-05-02 23:57:...|\n",
      "|--Rsj71PBe31h5Ylj...|2011-12-15 18:09:...|\n",
      "|--S62v0QgkqQaVUhF...|2010-12-25 07:04:...|\n",
      "|--SrzpvFLwP_YFwB_...|2011-02-10 03:51:...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f89e2e8748c0cf5d6287d9de48d6589",
     "grade": false,
     "grade_id": "cell-a2865bc601cc4990",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|hour|  count|\n",
      "+----+-------+\n",
      "|   1|1561788|\n",
      "|  19|1502271|\n",
      "|   0|1491176|\n",
      "|   2|1411255|\n",
      "|  20|1350195|\n",
      "|  23|1344117|\n",
      "|  18|1272108|\n",
      "|  22|1257437|\n",
      "|  21|1238808|\n",
      "|   3|1078939|\n",
      "|  17|1006102|\n",
      "|  16| 852076|\n",
      "|   4| 747453|\n",
      "|  15| 617830|\n",
      "|   5| 485129|\n",
      "|  14| 418340|\n",
      "|   6| 321764|\n",
      "|  13| 270145|\n",
      "|   7| 231417|\n",
      "|  12| 178910|\n",
      "|   8| 151065|\n",
      "|  11| 111769|\n",
      "|   9| 100568|\n",
      "|  10|  88486|\n",
      "+----+-------+\n",
      "\n",
      "CPU times: user 27.3 ms, sys: 9.69 ms, total: 36.9 ms\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf, explode\n",
    "from pyspark.sql.types import ArrayType,StringType\n",
    "from pyspark.sql.functions import hour, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "datesplit = udf(lambda x: x.split(','),ArrayType(StringType()))\n",
    "datesplit1 = udf(lambda x: int(x.split()[1].split(':')[0]), IntegerType())\n",
    "\n",
    "hours_by_checkin_count = checkin.withColumn(\"date_exploded\", f.explode(datesplit(col(\"date\")))) \\\n",
    "                      .withColumn('hour', datesplit1(col(\"date_exploded\"))) \\\n",
    "                      .groupby(['hour']).count().sort('count', ascending=False)\n",
    "\n",
    "hours_by_checkin_count.show(24) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340a16186b9323916455872bbf8889d5",
     "grade": false,
     "grade_id": "cell-51014951b91565ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert type(hours_by_checkin_count) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The top_useful_positive variable should be a Spark DataFrame.\"\n",
    "\n",
    "submitted = AutograderHelper.parse_spark_dataframe(hours_by_checkin_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab93f95c981e68fb61af722dbbd86c15",
     "grade": true,
     "grade_id": "cell-6c0f04ddb2c1d376",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 1 point (out of 20). This cell does not contain hidden tests.\n",
    "\n",
    "assert len(submitted) == 24, \\\n",
    "    \"The top_useful_positive DataFrame must have 24 rows.\"\n",
    "\n",
    "assert submitted[\"hour\"][0] == 1, \\\n",
    "    'The first row should have hour 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5646b8412015029c5a3fe2045cd30479",
     "grade": true,
     "grade_id": "cell-86eec1c279bef331",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 4 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ea483fd0b2cb398feba1584f7203740",
     "grade": false,
     "grade_id": "cell-f34ec996454b8d30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## -- COMMON USEFUL WORDS --\n",
    "\n",
    "Write a function that takes a Spark DataFrame as a parameter and returns a Spark DataFrame of the 50 most common words from *useful* reviews and their counts.\n",
    "\n",
    "- A \"useful review\" has 10 or more \"useful\" ratings.\n",
    "- Convert the text to lower case.\n",
    "- Use the provided `splitter()` function in a UDF to split the text into individual words.\n",
    "- Exclude the words in the provided `STOP_WORDS` set.\n",
    "- Returned DataFrame should have these columns:\n",
    "    - `word`\n",
    "    - `count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5e30222ef480b049506fed150c112d3",
     "grade": false,
     "grade_id": "cell-553c4a0f96a66555",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import lower, col\n",
    "import pyspark.sql.functions as funct\n",
    "\n",
    "\n",
    "def splitter(text):\n",
    "    WORD_RE = re.compile(r\"[\\w']+\")\n",
    "    return WORD_RE.findall(text)\n",
    "\n",
    "\n",
    "    STOP_WORDS = {\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"aint\", \"all\", \"also\", \"although\", \"am\", \"an\", \"and\", \"any\",\n",
    "    \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\",\n",
    "    \"check\", \"checked\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"don\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\",\n",
    "    \"further\", \"get\", \"go\", \"got\", \"had\", \"has\", \"have\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\n",
    "    \"himself\", \"his\", \"how\", \"however\", \"i\", \"i'd\", \"if\", \"i'm\", \"in\", \"into\", \"is\", \"it\", \"its\", \"it's\", \"itself\",\n",
    "    \"i've\", \"just\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"now\", \"of\", \"off\", \"on\", \"once\", \"one\",\n",
    "    \"online\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"paid\", \"place\", \"s\", \"said\", \n",
    "    \"same\", \"service\", \"she\", \"should\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\",\n",
    "    \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "    \"us\", \"very\", \"was\", \"we\", \"went\", \"were\", \"we've\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\",\n",
    "    \"why\", \"will\", \"with\", \"would\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "}\n",
    "\n",
    "def common_useful_words(reviews, limit=50):\n",
    "    \n",
    "    STOP_WORDS = {\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"aint\", \"all\", \"also\", \"although\", \"am\", \"an\", \"and\", \"any\",\n",
    "    \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\",\n",
    "    \"check\", \"checked\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"don\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\",\n",
    "    \"further\", \"get\", \"go\", \"got\", \"had\", \"has\", \"have\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\n",
    "    \"himself\", \"his\", \"how\", \"however\", \"i\", \"i'd\", \"if\", \"i'm\", \"in\", \"into\", \"is\", \"it\", \"its\", \"it's\", \"itself\",\n",
    "    \"i've\", \"just\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"now\", \"of\", \"off\", \"on\", \"once\", \"one\",\n",
    "    \"online\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"paid\", \"place\", \"s\", \"said\", \n",
    "    \"same\", \"service\", \"she\", \"should\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\",\n",
    "    \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "    \"us\", \"very\", \"was\", \"we\", \"went\", \"were\", \"we've\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\",\n",
    "    \"why\", \"will\", \"with\", \"would\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "}\n",
    "    \n",
    "    useful = review.filter(review[\"useful\"]>=10)\n",
    "    useful = useful.withColumn('text', lower(col('text')))\n",
    "\n",
    "    split = udf(lambda x: splitter(x), ArrayType(StringType()))\n",
    "    word = useful.select('text', split('text').alias('word'))\n",
    "            \n",
    "    data = word.withColumn('word', funct.explode('word'))\n",
    "    \n",
    "    count = data.groupBy('word').count().sort('count', ascending=False)\n",
    "    \n",
    "    most_common = count.filter(~funct.col('word').isin(STOP_WORDS)).limit(limit)\n",
    "    \n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a11b6eaf8c132f879f017240b47472a",
     "grade": false,
     "grade_id": "cell-b0171a78011d3ed9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we'll run it on the `review` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c249aec91877f6af2c6f33f2d6901e",
     "grade": false,
     "grade_id": "cell-f43fd0bde77106de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "common_useful_words_counts = common_useful_words(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66f2dfe045e0f528ec2fe93c13c3781d",
     "grade": false,
     "grade_id": "cell-d1aa94412d93396f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert type(common_useful_words_counts) == pyspark.sql.dataframe.DataFrame, \\\n",
    "    \"The common_useful_words_counts variable should be a Spark DataFrame.\"\n",
    "\n",
    "submitted = AutograderHelper.parse_spark_dataframe(common_useful_words_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e157eb7d83e6822785a86da7b14ccd0f",
     "grade": true,
     "grade_id": "cell-9c3ca29528e327be",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 2 points (out of 20). This cell does not contain hidden tests.\n",
    "\n",
    "assert len(submitted) == 50, \\\n",
    "    \"The common_useful_words_counts DataFrame must have 24 rows.\"\n",
    "\n",
    "assert submitted[\"word\"][0] == 'like', \\\n",
    "    'The first row should have word \"like\"'\n",
    "\n",
    "assert submitted[\"count\"][0] == 101251, \\\n",
    "    'The first row should have count 101251'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fe10c14a82026c86ac9bf8743dea9fe",
     "grade": true,
     "grade_id": "cell-d2a7766721f0da5b",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 6 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_big_data_scalable_data_processing_v3_assignment3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
